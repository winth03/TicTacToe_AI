{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import ttt as env\n",
    "\n",
    "STATES = 19683\n",
    "ACTIONS = 9\n",
    "\n",
    "Q = {}\n",
    "\n",
    "EPISODES = 20000 # how many times to run the enviornment from the beginning\n",
    "MAX_STEPS = 20  # max number of steps allowed for each run of enviornment\n",
    "\n",
    "LEARNING_RATE = 0.3  # learning rate\n",
    "GAMMA = 0.99\n",
    "\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ttt' from 'd:\\\\Projects\\\\TicTacToe_AI\\\\ttt.py'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 100.00%\n",
      "Average reward: 0.961288223812622\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for episode in range(EPISODES):\n",
    "  if (episode+1) % 1000 == 0:\n",
    "    clear_output()\n",
    "    print(f\"{(episode+1)} / {EPISODES} {((episode+1)/EPISODES)*100:.2f}%\", flush=True)\n",
    "\n",
    "  state = env.reset_game()\n",
    "  for _ in range(MAX_STEPS):\n",
    "\n",
    "    newValue = False\n",
    "    if state[0] in Q.keys():\n",
    "      qValues = Q[state[0]]\n",
    "    else:\n",
    "      Q[state[0]] = np.zeros(9)\n",
    "      newValue = True\n",
    "\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "      action = env.get_action()\n",
    "    else:\n",
    "      if np.count_nonzero(Q[state[0]] == np.max(Q[state[0]])) > 1:\n",
    "        actions = [i for i in range(len(qValues)) if qValues[i] == qValues.max()]\n",
    "        action = random.choice(actions)\n",
    "      elif newValue:\n",
    "        action = env.get_action()\n",
    "      else:\n",
    "        action = np.argmax(qValues)\n",
    "\n",
    "    next_state, winner, reward = env.take_action(action)\n",
    "\n",
    "    # learn from 4 rotated combinations\n",
    "    for i in range(len(state)):\n",
    "      if not (state[i] in Q.keys()):\n",
    "        Q[state[i]] = Q[state[0]]\n",
    "      if not (next_state[i] in Q.keys()):\n",
    "        Q[next_state[i]] = np.zeros(9)\n",
    "      Q[state[i]][action] = Q[state[i]][action] + LEARNING_RATE * \\\n",
    "        (reward + GAMMA * np.max(Q[next_state[i]]) - Q[state[i]][action])\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    if winner:\n",
    "      rewards.append(reward)\n",
    "      # epsilon -= 0.001\n",
    "      break\n",
    "\n",
    "# print(Q)\n",
    "print(f\"Average reward: {sum(rewards)/len(rewards)}\")\n",
    "# and now we can see our Q values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13366 [array([0.87998928, 0.82510676, 0.87834725, 0.86860202, 0.93185793,\n",
      "       0.78641792, 0.8721919 , 0.79631415, 0.8785366 ]), array([0.74217147, 0.73673996, 0.73036554, 0.75036268, 0.63597925,\n",
      "       0.77187047, 0.7474921 , 0.74771324, 0.74251954]), array([0.67218922, 0.73078094, 0.67441511, 0.66637967, 0.60527874,\n",
      "       0.74626398, 0.64589761, 0.68409094, 0.69686954]), array([0.74217147, 0.73673996, 0.73036554, 0.75036268, 0.63597925,\n",
      "       0.77187047, 0.7474921 , 0.74771324, 0.74251954]), array([0.67218922, 0.73078094, 0.67441511, 0.66637967, 0.60527874,\n",
      "       0.74626398, 0.64589761, 0.68409094, 0.69686954])]\n"
     ]
    }
   ],
   "source": [
    "x = list(Q.values())\n",
    "print(len(x), x[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Q\n",
    "fileName = \"q1.npy\"\n",
    "pathToFile = \"Q_Tables/\"+fileName\n",
    "data = dict(Q)\n",
    "np.save(pathToFile, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ef77c4912d0c20d0b0604a69c51b46c0ddf6a4dcf14f332031a777fb7703976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
